{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopDownParser:\n",
    "    def __init__(self, grammar):\n",
    "        self.grammar = grammar  # The CFG grammar from NLTK\n",
    "        self.start_symbol = grammar.start()  # Typically 'S'\n",
    "        self.tokens = []\n",
    "        self.index = 0  # Track current token index\n",
    "        self.backtrack = []  # Stack to store backtracking points\n",
    "        self.isBacktrack = False\n",
    "\n",
    "    def parse(self, tokens):\n",
    "        \"\"\"\n",
    "        Parse the tokens using recursive descent with backtracking.\n",
    "        :param tokens: The list of tokens to parse (input sentence).\n",
    "        :return: Parse tree if successful, None otherwise.\n",
    "        \"\"\"\n",
    "        self.tokens = tokens\n",
    "        self.index = 0  # Reset token index for new parsing attempt\n",
    "        self.prev_index = 0\n",
    "        self.backtrack = []\n",
    "        self.prev_tree = []\n",
    "        self.isBacktrack = False\n",
    "\n",
    "        parse_tree = self._parse_symbol(self.start_symbol)\n",
    "        \n",
    "        if parse_tree and self.index == len(tokens):\n",
    "            return parse_tree\n",
    "        \n",
    "        if self.backtrack and parse_tree:\n",
    "            self.isBacktrack = True\n",
    "            production, original_index = self.backtrack.pop()\n",
    "            self.index = original_index\n",
    "            self._parse_production(production.rhs(), parse_tree)\n",
    "            self.isBacktrack = False\n",
    "            return parse_tree\n",
    "        \n",
    "        return None  # Return None if parsing failed\n",
    "\n",
    "    def _parse_symbol(self, symbol):\n",
    "        \"\"\"\n",
    "        Recursively attempt to parse based on the current symbol.\n",
    "        :param symbol: The current grammar symbol (either non-terminal or terminal).\n",
    "        :return: Nested list representing parse tree if successful, None otherwise.\n",
    "        \"\"\"\n",
    "        if isinstance(symbol, nltk.Nonterminal):  # If non-terminal, expand it\n",
    "            productions = self.grammar.productions(lhs=symbol)\n",
    "            back_state_list = []\n",
    "            for i in range(len(productions)):\n",
    "                original_index = self.index\n",
    "                subtree = [symbol]  # Create a subtree for this symbol\n",
    "                if self._parse_production(productions[i].rhs(), subtree):  # Try expanding with this production\n",
    "                    back_state_list.append((subtree, self.index))\n",
    "                else:\n",
    "                    self.index = original_index  # Backtrack on failure\n",
    "            if back_state_list:\n",
    "                if len(back_state_list) > 1:\n",
    "                    self.backtrack.append(back_state_list[1:])\n",
    "                    print(self.backtrack)\n",
    "                return back_state_list[0][0]        \n",
    "            return None  # No production matched\n",
    "        else:  # If terminal, try to match it with the current token\n",
    "            print(symbol, self.tokens[self.index])\n",
    "            if self.index < len(self.tokens) and symbol == self.tokens[self.index]:\n",
    "                self.index += 1  # Consume the token\n",
    "                return symbol\n",
    "            else:\n",
    "                return None  # Terminal did not match\n",
    "\n",
    "    def _parse_production(self, rhs, subtree):\n",
    "        \"\"\"\n",
    "        Recursively parse each symbol in the right-hand side of a production.\n",
    "        :param rhs: The right-hand side symbols of a production.\n",
    "        :param subtree: The current subtree being built for the production.\n",
    "        :return: True if successfully matches all symbols in rhs, False otherwise.\n",
    "        \"\"\"\n",
    "        for symbol in rhs:\n",
    "            result = self._parse_symbol(symbol)  # Recursively parse each symbol\n",
    "            if result is None:\n",
    "                return False\n",
    "            \n",
    "            # if subtree[0] == nltk.Nonterminal(\"S\"):\n",
    "            #     self.prev_tree.append(subtree)\n",
    "                \n",
    "            subtree.append(result) \n",
    "\n",
    "        return True\n",
    "\n",
    "    def penn_tree_bank_format(self, tree):\n",
    "        \"\"\"\n",
    "        Pretty print the tree in a bracketed format similar to the Penn Treebank format.\n",
    "        \"\"\"\n",
    "        if tree is None:\n",
    "            return \"()\"\n",
    "        \n",
    "        if isinstance(tree, str):  # Leaf node (terminal)\n",
    "            return tree\n",
    "        else:\n",
    "            symbol = tree[0]\n",
    "            children = \" \".join(self.penn_tree_bank_format(child) for child in tree[1:])\n",
    "            return f\"({symbol} {children})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../output/grammar.txt', 'r') as rules_file:\n",
    "    rules = rules_file.read() \n",
    "    grammar = Grammar(rules=rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokinizer = Tokenizer(grammar.grammar)\n",
    "tokens, _ = tokinizer.tokenize(\"tớ không thử sản phẩm đó\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tớ', 'không', 'thử', 'sản phẩm', 'đó']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "hiện tại tớ\n",
      "bây giờ tớ\n",
      "5\n",
      "tôi tớ\n",
      "mình tớ\n",
      "tớ tớ\n",
      "anh không\n",
      "chị không\n",
      "7\n",
      "4\n",
      "đang không\n",
      "vẫn không\n",
      "sẽ không\n",
      "đã không\n",
      "3\n",
      "7\n",
      "có không\n",
      "muốn không\n",
      "thích không\n",
      "biết không\n",
      "mua không\n",
      "thử không\n",
      "quan tâm không\n",
      "7\n",
      "có không\n",
      "muốn không\n",
      "thích không\n",
      "biết không\n",
      "mua không\n",
      "thử không\n",
      "quan tâm không\n",
      "7\n",
      "có không\n",
      "muốn không\n",
      "thích không\n",
      "biết không\n",
      "mua không\n",
      "thử không\n",
      "quan tâm không\n",
      "1\n",
      "7\n",
      "bận không\n",
      "hào hứng không\n",
      "hài lòng không\n",
      "tốt không\n",
      "phù hợp không\n",
      "đắt không\n",
      "rẻ không\n",
      "4\n",
      "đang không\n",
      "vẫn không\n",
      "sẽ không\n",
      "đã không\n",
      "1\n",
      "7\n",
      "có không\n",
      "muốn không\n",
      "thích không\n",
      "biết không\n",
      "mua không\n",
      "thử không\n",
      "quan tâm không\n",
      "4\n",
      "đang không\n",
      "vẫn không\n",
      "sẽ không\n",
      "đã không\n",
      "1\n",
      "1\n",
      "không không\n",
      "7\n",
      "có thử\n",
      "muốn thử\n",
      "thích thử\n",
      "biết thử\n",
      "mua thử\n",
      "thử thử\n",
      "quan tâm sản phẩm\n",
      "2\n",
      "6\n",
      "nhu cầu sản phẩm\n",
      "sản phẩm sản phẩm\n",
      "dịch vụ đó\n",
      "thông tin đó\n",
      "cuộc gọi đó\n",
      "chương trình đó\n",
      "6\n",
      "nhu cầu đó\n",
      "sản phẩm đó\n",
      "dịch vụ đó\n",
      "thông tin đó\n",
      "cuộc gọi đó\n",
      "chương trình đó\n",
      "2\n",
      "1\n",
      "cái đó\n",
      "2\n",
      "6\n",
      "nhu cầu đó\n",
      "sản phẩm đó\n",
      "dịch vụ đó\n",
      "thông tin đó\n",
      "cuộc gọi đó\n",
      "chương trình đó\n",
      "6\n",
      "nhu cầu đó\n",
      "sản phẩm đó\n",
      "dịch vụ đó\n",
      "thông tin đó\n",
      "cuộc gọi đó\n",
      "chương trình đó\n"
     ]
    }
   ],
   "source": [
    "parser = TopDownParser(grammar.grammar)\n",
    "tree = parser.parse(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
